{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42a600a9",
   "metadata": {},
   "source": [
    "# PART1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77499b3e-195e-45e0-b13e-3fac742cc045",
   "metadata": {},
   "source": [
    "## Json import to openSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f81c3ba6-5e0b-4158-af9a-f005c05c8b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import createRecipesMap as crm\n",
    "\n",
    "crm.CreateRecipesMap(\"../jsonData/recipe_queries_results.json\", '../jsonData/recipesMap.json').createMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1161acd6-e0c8-4d54-9b82-3816aba95707",
   "metadata": {},
   "source": [
    "## Login to openSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e0c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import loginOpenSearch as lop\n",
    "\n",
    "login = lop.LoginOpenSearch(\"../jsonData/openSearchConfig.json\").login()\n",
    "    \n",
    "client = login[0]\n",
    "index_name = login[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95847a2a-0256-406f-a2f2-ddd97bb3c664",
   "metadata": {},
   "source": [
    "## Create index structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e6b04d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import createIndexes as ci\n",
    "\n",
    "ci.CreateIndexes(client, index_name).createIndexStructure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6abb6c-d050-476b-a517-f0062433f2e6",
   "metadata": {},
   "source": [
    "## Choose the tokenizer and model that will be used in the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6acad3-7c01-4bf1-8540-9f2d71c40e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/msmarco-distilbert-base-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/msmarco-distilbert-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90996957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import computeEmbeddings as ce\n",
    "\n",
    "ce.ComputeEmbeddings(\"../jsonData/recipesMap.json\",\"../jsonData/recipesEmbeddingsMap.json\", tokenizer, model).createMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7060fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import indexRecipes as ir\n",
    "\n",
    "ir.IndexRecipes(\"../jsonData/recipesMap.json\", \"../jsonData/recipesEmbeddingsMap.json\", client, index_name).indexRecipes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810b7b24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import search as s\n",
    "\n",
    "s.Search(client, index_name, tokenizer, model).queryOpenSearch('Holiday Salad', 5,None, None, [\"salads\"], [\"lupine\"], None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fb377f-fce9-4b0e-9ed3-4f84415614d5",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f46b0ad-3964-4e87-bb3f-d3c1c6eae494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import searchJson as sj\n",
    "metrics = sj.SearchJson(client, index_name, tokenizer, model)\n",
    "metrics.searchJson(\"../jsonData/cleanAnnotations.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e6517c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "delete this sentence to run\n",
    "if client.indices.exists(index=index_name):\n",
    "    # Delete the index.\n",
    "    response = client.indices.delete(\n",
    "        index = index_name,\n",
    "        timeout = \"600s\"\n",
    "    )\n",
    "    print('\\nDeleting index:')\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93a256a",
   "metadata": {},
   "source": [
    "# PART2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01766b41",
   "metadata": {},
   "source": [
    "## Compute the step similarity matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0173ab",
   "metadata": {},
   "source": [
    "### Compute the steps json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "736ee30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stepsCalculator as sc\n",
    "\n",
    "sc.CreateStepsMaps(\"../jsonData/recipesMap.json\", '../jsonData/stepsImage.json', '../jsonData/stepsNoImage.json').createMaps()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b360a3f8",
   "metadata": {},
   "source": [
    "### Compute the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84a1adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/msmarco-distilbert-base-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/msmarco-distilbert-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9186215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import computeImagesEmbeddings as cie\n",
    "\n",
    "cie.ComputeImagesEmbeddings(\"../jsonData/stepsImage.json\",\"../jsonData/stepsNoImage.json\",\"../jsonData/stepsImageEmbeddingsMap.json\",\"../jsonData/stepsNoImageEmbeddingsMap.json\", tokenizer, model).createMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f39201",
   "metadata": {},
   "source": [
    "### Compute the similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "380ed141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.18038417  0.32493275  0.09035419 ...  0.24216047  0.1828222\n",
      "   0.06139156]\n",
      " [ 0.22687672  0.3896319   0.36241928 ...  0.33001146  0.29410326\n",
      "   0.21193336]\n",
      " [ 0.2823929   0.29953444  0.2362206  ...  0.2590037   0.15724806\n",
      "   0.09927286]\n",
      " ...\n",
      " [ 0.18877986  0.06847328  0.1471263  ...  0.18271409  0.20773083\n",
      "   0.1412945 ]\n",
      " [-0.03327034 -0.04340815  0.10297828 ... -0.08764414 -0.04812049\n",
      "  -0.03889523]\n",
      " [ 0.21104099  0.1107926   0.2918464  ...  0.3544004   0.27908713\n",
      "   0.1592933 ]]\n",
      "804\n"
     ]
    }
   ],
   "source": [
    "import computeMatrix as cm\n",
    "\n",
    "imageSimilarityMatrix = cm.ComputeMatrix(\"../jsonData/stepsImageEmbeddingsMap.json\", \"../jsonData/stepsNoImageEmbeddingsMap.json\").createMatrix()\n",
    "print(imageSimilarityMatrix)\n",
    "print(len(imageSimilarityMatrix[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15542b81-6240-495b-8627-8c2082397b09",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,224,224) (3,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1505524/586158466.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcomputeClipOutput\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mComputeClipOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageSimilarityMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../jsonData/stepsImage.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../jsonData/stepsNoImage.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"images/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/mpdw-proj/computeClipOutput.py\u001b[0m in \u001b[0;36mgetImage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mVL_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mVL_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/clip/processing_clip.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, images, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mimage_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/clip/feature_extraction_clip.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, images, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenter_crop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrop_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_normalize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_std\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;31m# return as BatchFeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/clip/feature_extraction_clip.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenter_crop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrop_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_normalize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_std\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;31m# return as BatchFeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/image_utils.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(self, image, mean, std)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBILINEAR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_to_square\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,224,224) (3,) "
     ]
    }
   ],
   "source": [
    "import computeClipOutput as cco\n",
    "\n",
    "cco.ComputeClipOutput(imageSimilarityMatrix, \"../jsonData/stepsImage.json\", \"../jsonData/stepsNoImage.json\", \"images/\").getImage()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b01e16f685b97ac6c048476024a823da546713321bc2babde743de74f38aea3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
