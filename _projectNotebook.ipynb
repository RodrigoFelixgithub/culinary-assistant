{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42a600a9",
   "metadata": {},
   "source": [
    "# PART1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77499b3e-195e-45e0-b13e-3fac742cc045",
   "metadata": {},
   "source": [
    "## Json import to openSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81c3ba6-5e0b-4158-af9a-f005c05c8b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import createRecipesMap as crm\n",
    "\n",
    "crm.CreateRecipesMap(\"../jsonData/recipe_queries_results.json\", '../jsonData/recipesMap.json').createMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1161acd6-e0c8-4d54-9b82-3816aba95707",
   "metadata": {},
   "source": [
    "## Login to openSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e0c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import loginOpenSearch as lop\n",
    "\n",
    "login = lop.LoginOpenSearch(\"../jsonData/openSearchConfig.json\").login()\n",
    "    \n",
    "client = login[0]\n",
    "index_name = login[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95847a2a-0256-406f-a2f2-ddd97bb3c664",
   "metadata": {},
   "source": [
    "## Create index structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e6b04d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import createIndexes as ci\n",
    "\n",
    "ci.CreateIndexes(client, index_name).createIndexStructure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6abb6c-d050-476b-a517-f0062433f2e6",
   "metadata": {},
   "source": [
    "## Choose the tokenizer and model that will be used in the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6acad3-7c01-4bf1-8540-9f2d71c40e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/msmarco-distilbert-base-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/msmarco-distilbert-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90996957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import computeEmbeddings as ce\n",
    "\n",
    "ce.ComputeEmbeddings(\"../jsonData/recipesMap.json\",\"../jsonData/recipesEmbeddingsMap.json\", tokenizer, model).createMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7060fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import indexRecipes as ir\n",
    "\n",
    "ir.IndexRecipes(\"../jsonData/recipesMap.json\", \"../jsonData/recipesEmbeddingsMap.json\", client, index_name).indexRecipes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810b7b24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import search as s\n",
    "\n",
    "s.Search(client, index_name, tokenizer, model).queryOpenSearch('Holiday Salad', 5,None, None, [\"salads\"], [\"lupine\"], None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fb377f-fce9-4b0e-9ed3-4f84415614d5",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f46b0ad-3964-4e87-bb3f-d3c1c6eae494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import searchJson as sj\n",
    "metrics = sj.SearchJson(client, index_name, tokenizer, model)\n",
    "metrics.searchJson(\"../jsonData/cleanAnnotations.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e6517c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "delete this sentence to run\n",
    "if client.indices.exists(index=index_name):\n",
    "    # Delete the index.\n",
    "    response = client.indices.delete(\n",
    "        index = index_name,\n",
    "        timeout = \"600s\"\n",
    "    )\n",
    "    print('\\nDeleting index:')\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93a256a",
   "metadata": {},
   "source": [
    "# PART2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01766b41",
   "metadata": {},
   "source": [
    "## Compute the step similarity matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0173ab",
   "metadata": {},
   "source": [
    "### Compute the steps json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736ee30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stepsCalculator as sc\n",
    "\n",
    "sc.CreateStepsMaps(\"../jsonData/recipesMap.json\", '../jsonData/stepsImage.json', '../jsonData/stepsNoImage.json').createMaps()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b360a3f8",
   "metadata": {},
   "source": [
    "### Compute the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b22384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9186215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import computeImagesEmbeddings as cie\n",
    "\n",
    "cie.ComputeImagesEmbeddings(\"../jsonData/stepsImage.json\",\"../jsonData/stepsNoImage.json\",\"../jsonData/stepsImageEmbeddingsMap.json\",\"../jsonData/stepsNoImageEmbeddingsMap.json\",\"images/\").createMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f39201",
   "metadata": {},
   "source": [
    "### Compute the similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380ed141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import computeMatrix as cm\n",
    "\n",
    "imageSimilarityMatrix = cm.ComputeMatrix(\"../jsonData/stepsImageEmbeddingsMap.json\", \"../jsonData/stepsNoImageEmbeddingsMap.json\").createMatrix()\n",
    "print(imageSimilarityMatrix)\n",
    "print(len(imageSimilarityMatrix[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e73ddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getImage as gi\n",
    "\n",
    "gi.GetImage(imageSimilarityMatrix, \"../jsonData/stepsImage.json\", \"../jsonData/stepsNoImage.json\", \"images/\",\"../jsonData/recipesMap.json\").getImageFunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15542b81-6240-495b-8627-8c2082397b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import computeClipOutput as cco\n",
    "\n",
    "#image = cco.ComputeClipOutput(imageSimilarityMatrix, \"../jsonData/stepsImage.json\", \"../jsonData/stepsNoImage.json\", \"images/\",\"../jsonData/recipesMap.json\").getImage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9940ebd0",
   "metadata": {},
   "source": [
    "# PART3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce0b034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import transformers\n",
    "import json\n",
    "import loginOpenSearch as lop\n",
    "import search as s\n",
    "import extractiveQA as eq\n",
    "\n",
    "import random\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "\n",
    "model_finetuned = '/user/data/public/twiz-intent-model'\n",
    "with open(os.path.join(model_finetuned + '/all_intents.json'), 'r') as all_intents_json:\n",
    "    all_intents = json.load(all_intents_json) # contains the written out names of intents. also implicitly\n",
    "\n",
    "tokenizer_name = 'roberta-base' # try 'bert-base-uncased', 'bert-base-cased', 'bert-large-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name) # loads a tokenizer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_finetuned, num_labels=len(all_intents)) # Loads the BERT model weights\n",
    "\n",
    "login = lop.LoginOpenSearch(\"../jsonData/openSearchConfig.json\").login()\n",
    "openSearchTokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/msmarco-distilbert-base-v2\")\n",
    "openSearchModel = AutoModel.from_pretrained(\"sentence-transformers/msmarco-distilbert-base-v2\")\n",
    "\n",
    "searchEngine = s.Search(login[0], login[1], openSearchTokenizer, openSearchModel)\n",
    "qaExtractor = eq.ExtractiveQA()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2146dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stateMachine\n",
    "turing = stateMachine.StateMachine(tokenizer,model, all_intents,searchEngine, qaExtractor)\n",
    "\n",
    "#response = 'hello, i would like to cook spaghetti'\n",
    "response = 'I\\'m in the mood for chicken.'\n",
    "intent = turing.getIntent(response)\n",
    "turing.setUserResponse(response)\n",
    "print(intent)\n",
    "getattr(turing, intent)()\n",
    "\n",
    "response = 'i would like my recipe to contain some apples and some onions but not bananas'\n",
    "response = 'no'\n",
    "intent = turing.getIntent(response)\n",
    "turing.setUserResponse(response)\n",
    "print(intent)\n",
    "getattr(turing, intent)()\n",
    "\n",
    "response = 'i would like my recipe to contain some apples and some onions but not bananas' \n",
    "response = 'no'\n",
    "intent = turing.getIntent(response)\n",
    "turing.setUserResponse(response)\n",
    "print(intent)\n",
    "getattr(turing, intent)()\n",
    "\n",
    "\n",
    "response = 'yes i would like my recipe to be vegetarian or gluten-free please' \n",
    "response = 'no'\n",
    "intent = turing.getIntent(response)\n",
    "turing.setUserResponse(response)\n",
    "print(intent)\n",
    "getattr(turing, intent)()\n",
    "\n",
    "\n",
    "#response = 'yes i would like the recipe to be under 60 minutes' \n",
    "response = 'yes i would like the recipe to be under sixty minutes' \n",
    "response = 'no'\n",
    "intent = turing.getIntent(response)\n",
    "turing.setUserResponse(response)\n",
    "print(intent)\n",
    "getattr(turing, intent)()\n",
    "\n",
    "response = 'i would like the Chicken Shawarma please' \n",
    "intent = turing.getIntent(response)\n",
    "turing.setUserResponse(response)\n",
    "print(intent)\n",
    "getattr(turing, intent)()\n",
    "\n",
    "# response = 'yes' \n",
    "# intent = turing.getIntent(response)\n",
    "# turing.setUserResponse(response)\n",
    "# print(intent)\n",
    "# getattr(turing, intent)()\n",
    "\n",
    "# response = 'yes' \n",
    "# intent = turing.getIntent(response)\n",
    "# turing.setUserResponse(response)\n",
    "# print(intent)\n",
    "# getattr(turing, intent)()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda87214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stateMachine\n",
    "turing = stateMachine.StateMachine(tokenizer,model, all_intents, searchEngine, qaExtractor)\n",
    "while(turing.state != 'terminar'):\n",
    "\n",
    "    response = input(\"USER:\")\n",
    "    intent = turing.getIntent(response)\n",
    "    turing.setUserResponse(response)\n",
    "    try: \n",
    "        getattr(turing, intent)() \n",
    "    except Exception as e:\n",
    "        print ('pls refrase')\n",
    "        continue\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21aeea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "qaExtractor.extractAnswer(\"What do you want to cook?\", \"I'm in the mood for some bacon and eggs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3be54c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, HTML, display\n",
    "\n",
    "with open('../jsonData/recipesMapWithImages.json', \"r\") as read_file:\n",
    "    recipesMap = json.load(read_file)\n",
    "\n",
    "def displayResults(title, img, totalTime, rating):\n",
    "    display(HTML(f\"\"\"\n",
    "        <div class=\"row\" style=\"display: flex; align-items: center; border-style: double;\">\n",
    "            <div class=\"column\">\n",
    "                <img src={img} style=\"width:200px; margin-right:20px\"/>\n",
    "            </div>\n",
    "            <div class=\"column\">\n",
    "                <div class=\"row\"><b>{title}</b> </div>\n",
    "                <div class=\"row\">Preparation time: {totalTime}</div>\n",
    "                <div class=\"row\">Rating: {rating}</div>\n",
    "            </div>\n",
    "        </div>\n",
    "    \"\"\"))\n",
    "\n",
    "myjson = searchEngine.queryOpenSearch('Holiday Salad', 10,None, None, [\"salads\"], [\"lupine\"], None)\n",
    "\n",
    "recipesarray = [recipe['fields']['recipeId'][0] for recipe in myjson['hits']['hits']]\n",
    "\n",
    "\n",
    "for i in recipesarray:\n",
    "    title = recipesMap[i]['recipe']['displayName']\n",
    "    img = recipesMap[i]['recipe']['images'][0]['url']\n",
    "    totalTime = str(recipesMap[i]['recipe']['totalTimeMinutes']) + ' minutes' if recipesMap[i]['recipe']['totalTimeMinutes'] != None else '-'\n",
    "    rating = str(recipesMap[i]['rating']['ratingValue']) + '/5' if recipesMap[i]['rating'] != None else '-'\n",
    "    displayResults(title,img,totalTime,rating)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4f3ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy as spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "sentence = 'vegetarian or gluten-free'\n",
    "idk = nlp(sentence)\n",
    "output = []\n",
    "for token in idk:\n",
    "    if(token.is_alpha):\n",
    "        toRemove = token.text\n",
    "    print\n",
    "    output.append(token)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d749e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy as spacy\n",
    "from spacy import displacy\n",
    "\n",
    "\n",
    "def checkNegative(keyword):\n",
    "    return \"free\" in keyword or \"no\" in keyword\n",
    "\n",
    "def cleanNegativeWord(keyword):\n",
    "    keyword = keyword.replace(\"free\",\"\").strip()\n",
    "    keyword = keyword.replace(\"no \",\"\").strip()\n",
    "    return keyword\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "sentence = 'vegetarian or gluten-free or fish-free and nice'\n",
    "array = sentence.split()\n",
    "keywordsPositive = []\n",
    "keywordsNegative = []\n",
    "\n",
    "doc = nlp(sentence)\n",
    "for token in doc:\n",
    "    if(token.is_stop ):\n",
    "        array.remove(token.text)\n",
    "\n",
    "print(array)\n",
    "\n",
    "for keyword in array:\n",
    "    keywordDoc = nlp(keyword)\n",
    "    keywordString = ' '.join([token.lemma_ for token in keywordDoc if not token.is_stop and token.is_alpha])\n",
    "    print(keywordString)\n",
    "    if checkNegative(keyword):\n",
    "        keywordCleaned = cleanNegativeWord(keywordString)\n",
    "        keywordsNegative.append(keywordCleaned)\n",
    "    else:\n",
    "        keywordsPositive.append(keywordString)\n",
    "\n",
    "\n",
    "\n",
    "print(keywordsNegative)\n",
    "\n",
    "print(keywordsPositive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec46b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2int(textnum, numwords={}):\n",
    "    if not numwords:\n",
    "      units = [\n",
    "        \"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\",\n",
    "        \"nine\", \"ten\", \"eleven\", \"twelve\", \"thirteen\", \"fourteen\", \"fifteen\",\n",
    "        \"sixteen\", \"seventeen\", \"eighteen\", \"nineteen\",\n",
    "      ]\n",
    "\n",
    "      tens = [\"\", \"\", \"twenty\", \"thirty\", \"forty\", \"fifty\", \"sixty\", \"seventy\", \"eighty\", \"ninety\"]\n",
    "\n",
    "      scales = [\"hundred\", \"thousand\", \"million\", \"billion\", \"trillion\"]\n",
    "\n",
    "      numwords[\"and\"] = (1, 0)\n",
    "      for idx, word in enumerate(units):    numwords[word] = (1, idx)\n",
    "      for idx, word in enumerate(tens):     numwords[word] = (1, idx * 10)\n",
    "      for idx, word in enumerate(scales):   numwords[word] = (10 ** (idx * 3 or 2), 0)\n",
    "\n",
    "    current = result = 0\n",
    "    for word in textnum.split():\n",
    "        if word not in numwords:\n",
    "          raise Exception(\"Illegal word: \" + word)\n",
    "\n",
    "        scale, increment = numwords[word]\n",
    "        current = current * scale + increment\n",
    "        if scale > 100:\n",
    "            result += current\n",
    "            current = 0\n",
    "\n",
    "    return result + current\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada604cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2int(\"sixty\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e30e07544ccebc78dacd6421da111f7ec20c267e40e3fb45cd6c16b14155975"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('felixines': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
