{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42a600a9",
   "metadata": {},
   "source": [
    "# PART1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77499b3e-195e-45e0-b13e-3fac742cc045",
   "metadata": {},
   "source": [
    "## Json import to openSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81c3ba6-5e0b-4158-af9a-f005c05c8b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import createRecipesMap as crm\n",
    "\n",
    "crm.CreateRecipesMap(\"../jsonData/recipe_queries_results.json\", '../jsonData/recipesMap.json').createMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1161acd6-e0c8-4d54-9b82-3816aba95707",
   "metadata": {},
   "source": [
    "## Login to openSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e0c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import loginOpenSearch as lop\n",
    "\n",
    "login = lop.LoginOpenSearch(\"../jsonData/openSearchConfig.json\").login()\n",
    "    \n",
    "client = login[0]\n",
    "index_name = login[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95847a2a-0256-406f-a2f2-ddd97bb3c664",
   "metadata": {},
   "source": [
    "## Create index structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e6b04d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import createIndexes as ci\n",
    "\n",
    "ci.CreateIndexes(client, index_name).createIndexStructure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6abb6c-d050-476b-a517-f0062433f2e6",
   "metadata": {},
   "source": [
    "## Choose the tokenizer and model that will be used in the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6acad3-7c01-4bf1-8540-9f2d71c40e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/msmarco-distilbert-base-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/msmarco-distilbert-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90996957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import computeEmbeddings as ce\n",
    "\n",
    "ce.ComputeEmbeddings(\"../jsonData/recipesMap.json\",\"../jsonData/recipesEmbeddingsMap.json\", tokenizer, model).createMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7060fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import indexRecipes as ir\n",
    "\n",
    "ir.IndexRecipes(\"../jsonData/recipesMap.json\", \"../jsonData/recipesEmbeddingsMap.json\", client, index_name).indexRecipes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810b7b24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import search as s\n",
    "\n",
    "s.Search(client, index_name, tokenizer, model).queryOpenSearch('Holiday Salad', 5,None, None, [\"salads\"], [\"lupine\"], None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fb377f-fce9-4b0e-9ed3-4f84415614d5",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f46b0ad-3964-4e87-bb3f-d3c1c6eae494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import searchJson as sj\n",
    "metrics = sj.SearchJson(client, index_name, tokenizer, model)\n",
    "metrics.searchJson(\"../jsonData/cleanAnnotations.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e6517c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "delete this sentence to run\n",
    "if client.indices.exists(index=index_name):\n",
    "    # Delete the index.\n",
    "    response = client.indices.delete(\n",
    "        index = index_name,\n",
    "        timeout = \"600s\"\n",
    "    )\n",
    "    print('\\nDeleting index:')\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93a256a",
   "metadata": {},
   "source": [
    "# PART2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01766b41",
   "metadata": {},
   "source": [
    "## Compute the step similarity matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0173ab",
   "metadata": {},
   "source": [
    "### Compute the steps json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736ee30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stepsCalculator as sc\n",
    "\n",
    "sc.CreateStepsMaps(\"../jsonData/recipesMap.json\", '../jsonData/stepsImage.json', '../jsonData/stepsNoImage.json').createMaps()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b360a3f8",
   "metadata": {},
   "source": [
    "### Compute the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b22384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9186215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import computeImagesEmbeddings as cie\n",
    "\n",
    "cie.ComputeImagesEmbeddings(\"../jsonData/stepsImage.json\",\"../jsonData/stepsNoImage.json\",\"../jsonData/stepsImageEmbeddingsMap.json\",\"../jsonData/stepsNoImageEmbeddingsMap.json\",\"images/\").createMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f39201",
   "metadata": {},
   "source": [
    "### Compute the similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380ed141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import computeMatrix as cm\n",
    "\n",
    "imageSimilarityMatrix = cm.ComputeMatrix(\"../jsonData/stepsImageEmbeddingsMap.json\", \"../jsonData/stepsNoImageEmbeddingsMap.json\").createMatrix()\n",
    "print(imageSimilarityMatrix)\n",
    "print(len(imageSimilarityMatrix[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e73ddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getImage as gi\n",
    "\n",
    "gi.GetImage(imageSimilarityMatrix, \"../jsonData/stepsImage.json\", \"../jsonData/stepsNoImage.json\", \"images/\",\"../jsonData/recipesMap.json\").getImageFunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15542b81-6240-495b-8627-8c2082397b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import computeClipOutput as cco\n",
    "\n",
    "#image = cco.ComputeClipOutput(imageSimilarityMatrix, \"../jsonData/stepsImage.json\", \"../jsonData/stepsNoImage.json\", \"images/\",\"../jsonData/recipesMap.json\").getImage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9940ebd0",
   "metadata": {},
   "source": [
    "# PART3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cce0b034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------- INDEX SETTINGS\n",
      "{'user209': {'settings': {'index': {'creation_date': '1649609449190',\n",
      "                                    'knn': 'true',\n",
      "                                    'number_of_replicas': '0',\n",
      "                                    'number_of_shards': '4',\n",
      "                                    'provided_name': 'user209',\n",
      "                                    'refresh_interval': '1s',\n",
      "                                    'uuid': 'zYvHS7n3SS6ejuPIp7Ikhw',\n",
      "                                    'version': {'created': '135238227'}}}}}\n",
      "\n",
      "----------------------------------------------------------------------------------- INDEX MAPPINGS\n",
      "{'user209': {'mappings': {'properties': {'description': {'similarity': 'BM25',\n",
      "                                                         'type': 'text'},\n",
      "                                         'ingredients': {'type': 'keyword'},\n",
      "                                         'negative_Keywords': {'type': 'keyword'},\n",
      "                                         'positive_Keywords': {'type': 'keyword'},\n",
      "                                         'recipeId': {'type': 'keyword'},\n",
      "                                         'sentence_embedding_description': {'dimension': 768,\n",
      "                                                                            'method': {'engine': 'faiss',\n",
      "                                                                                       'name': 'hnsw',\n",
      "                                                                                       'parameters': {'ef_construction': 384,\n",
      "                                                                                                      'm': 48},\n",
      "                                                                                       'space_type': 'innerproduct'},\n",
      "                                                                            'type': 'knn_vector'},\n",
      "                                         'sentence_embedding_title': {'dimension': 768,\n",
      "                                                                      'method': {'engine': 'faiss',\n",
      "                                                                                 'name': 'hnsw',\n",
      "                                                                                 'parameters': {'ef_construction': 384,\n",
      "                                                                                                'm': 48},\n",
      "                                                                                 'space_type': 'innerproduct'},\n",
      "                                                                      'type': 'knn_vector'},\n",
      "                                         'time': {'type': 'integer'},\n",
      "                                         'title': {'similarity': 'BM25',\n",
      "                                                   'type': 'text'}}}}}\n",
      "\n",
      "----------------------------------------------------------------------------------- INDEX #DOCs\n",
      "{'count': 994, '_shards': {'total': 4, 'successful': 4, 'skipped': 0, 'failed': 0}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import transformers\n",
    "import json\n",
    "import loginOpenSearch as lop\n",
    "import search as s\n",
    "import extractiveQA as eq\n",
    "\n",
    "import random\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "\n",
    "model_finetuned = '/user/data/public/twiz-intent-model'\n",
    "with open(os.path.join(model_finetuned + '/all_intents.json'), 'r') as all_intents_json:\n",
    "    all_intents = json.load(all_intents_json) # contains the written out names of intents. also implicitly\n",
    "\n",
    "tokenizer_name = 'roberta-base' # try 'bert-base-uncased', 'bert-base-cased', 'bert-large-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name) # loads a tokenizer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_finetuned, num_labels=len(all_intents)) # Loads the BERT model weights\n",
    "\n",
    "login = lop.LoginOpenSearch(\"../jsonData/openSearchConfig.json\").login()\n",
    "openSearchTokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/msmarco-distilbert-base-v2\")\n",
    "openSearchModel = AutoModel.from_pretrained(\"sentence-transformers/msmarco-distilbert-base-v2\")\n",
    "\n",
    "searchEngine = s.Search(login[0], login[1], openSearchTokenizer, openSearchModel)\n",
    "qaExtractor = eq.ExtractiveQA()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2146dfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm a cooking assistant and I'm here to help you cook anything you want. What would you like to prepare today?\n",
      "IdentifyProcessIntent\n",
      "carbonara\n",
      "Ok! I'll now ask you some questions to find the carbonara recipe you're looking for!\n",
      "Are there any desired ingredients you'd like the recipe to have? If so, could you enumerate them?\n",
      "IngredientsConfirmationIntent\n",
      "['apples', 'onions']\n",
      "Ok, I'll take apples, onions in consideration.\n",
      "Are there any ingredients you really don't want in the recipe? If so, could you also enumerate them?\n",
      "IngredientsConfirmationIntent\n",
      "['bananas']\n",
      "Got it, I'll find recipes which don't contain any bananas.\n",
      "Should the recipe follow any dietary requirements?\n",
      "For example, does it need to be vegan or gluten-free?\n",
      "AMAZON.YesIntent\n",
      "vegetarian or gluten-free\n",
      "keywords: ['vegetarian', 'gluten-free']\n",
      "keywordsNegative: ['gluten']\n",
      "keywordsPositive: ['vegetarian']\n",
      "Ok, I'll prioritize recipes that have vegetarian, gluten-free requirements.\n",
      "Last question! Are there any time restrictions for the food preparation? If so, how many minutes would you like it to take?\n",
      "AMAZON.NoIntent\n",
      "Very well, I won't take any time restriction into consideration.\n",
      "Done! I have found some recipes that fit your description.\n",
      "Which one would you like to see?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import stateMachine\n",
    "turing = stateMachine.StateMachine(tokenizer,model, all_intents,searchEngine, qaExtractor)\n",
    "\n",
    "#response = 'hello, i would like to cook spaghetti'\n",
    "response = 'I\\'m in the mood for some carbonara.'\n",
    "intent = turing.getIntent(response)\n",
    "turing.setUserResponse(response)\n",
    "print(intent)\n",
    "getattr(turing, intent)()\n",
    "\n",
    "response = 'i would like my recipe to contain some apples and some onions but not bananas'\n",
    "intent = turing.getIntent(response)\n",
    "turing.setUserResponse(response)\n",
    "print(intent)\n",
    "getattr(turing, intent)()\n",
    "\n",
    "response = 'i would like my recipe to contain some apples and some onions but not bananas' \n",
    "intent = turing.getIntent(response)\n",
    "turing.setUserResponse(response)\n",
    "print(intent)\n",
    "getattr(turing, intent)()\n",
    "\n",
    "\n",
    "response = 'yes i would like my recipe to be vegetarian or gluten-free please' \n",
    "intent = turing.getIntent(response)\n",
    "turing.setUserResponse(response)\n",
    "print(intent)\n",
    "getattr(turing, intent)()\n",
    "\n",
    "\n",
    "#response = 'yes i would like the recipe to be under 60 minutes' \n",
    "response = 'yes i would like the recipe to be under sixty minutes' \n",
    "intent = turing.getIntent(response)\n",
    "turing.setUserResponse(response)\n",
    "print(intent)\n",
    "getattr(turing, intent)()\n",
    "\n",
    "response = 'the number 5 pls' \n",
    "intent = turing.getIntent(response)\n",
    "turing.setUserResponse(response)\n",
    "print(intent)\n",
    "getattr(turing, intent)()\n",
    "\n",
    "# response = 'yes' \n",
    "# intent = turing.getIntent(response)\n",
    "# turing.setUserResponse(response)\n",
    "# print(intent)\n",
    "# getattr(turing, intent)()\n",
    "\n",
    "# response = 'yes' \n",
    "# intent = turing.getIntent(response)\n",
    "# turing.setUserResponse(response)\n",
    "# print(intent)\n",
    "# getattr(turing, intent)()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eda87214",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/user/home/user209/mpdw-proj/_projectNotebook.ipynb Cell 30'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223139332e3133362e3132322e313332222c2275736572223a2275736572323039222c22706f7274223a31323033347d/user/home/user209/mpdw-proj/_projectNotebook.ipynb#ch0000031vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mstateMachine\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223139332e3133362e3132322e313332222c2275736572223a2275736572323039222c22706f7274223a31323033347d/user/home/user209/mpdw-proj/_projectNotebook.ipynb#ch0000031vscode-remote?line=1'>2</a>\u001b[0m turing \u001b[39m=\u001b[39m stateMachine\u001b[39m.\u001b[39mStateMachine(tokenizer,model, all_intents, searchEngine, qaExtractor)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223139332e3133362e3132322e313332222c2275736572223a2275736572323039222c22706f7274223a31323033347d/user/home/user209/mpdw-proj/_projectNotebook.ipynb#ch0000031vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mwhile\u001b[39;00m(turing\u001b[39m.\u001b[39mstate \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mterminar\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223139332e3133362e3132322e313332222c2275736572223a2275736572323039222c22706f7274223a31323033347d/user/home/user209/mpdw-proj/_projectNotebook.ipynb#ch0000031vscode-remote?line=4'>5</a>\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mUSER:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "import stateMachine\n",
    "turing = stateMachine.StateMachine(tokenizer,model, all_intents, searchEngine, qaExtractor)\n",
    "while(turing.state != 'terminar'):\n",
    "\n",
    "    response = input(\"USER:\")\n",
    "    intent = turing.getIntent(response)\n",
    "    turing.setUserResponse(response)\n",
    "    try: \n",
    "        getattr(turing, intent)() \n",
    "    except Exception as e:\n",
    "        print ('pls refrase')\n",
    "        continue\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b21aeea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.7682953476905823,\n",
       " 'start': 25,\n",
       " 'end': 39,\n",
       " 'answer': 'bacon and eggs'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qaExtractor.extractAnswer(\"What do you want to cook?\", \"I'm in the mood for some bacon and eggs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3be54c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, HTML, display\n",
    "\n",
    "with open('../jsonData/recipesMapWithImages.json', \"r\") as read_file:\n",
    "    recipesMap = json.load(read_file)\n",
    "\n",
    "def displayResults(title, img, totalTime, rating):\n",
    "    display(HTML(f\"\"\"\n",
    "        <div class=\"row\" style=\"display: flex; align-items: center; border-style: double;\">\n",
    "            <div class=\"column\">\n",
    "                <img src={img} style=\"width:200px; margin-right:20px\"/>\n",
    "            </div>\n",
    "            <div class=\"column\">\n",
    "                <div class=\"row\"><b>{title}</b> </div>\n",
    "                <div class=\"row\">Preparation time: {totalTime}</div>\n",
    "                <div class=\"row\">Rating: {rating}</div>\n",
    "            </div>\n",
    "        </div>\n",
    "    \"\"\"))\n",
    "\n",
    "myjson = searchEngine.queryOpenSearch('Holiday Salad', 10,None, None, [\"salads\"], [\"lupine\"], None)\n",
    "\n",
    "recipesarray = [recipe['fields']['recipeId'][0] for recipe in myjson['hits']['hits']]\n",
    "\n",
    "\n",
    "for i in recipesarray:\n",
    "    title = recipesMap[i]['recipe']['displayName']\n",
    "    img = recipesMap[i]['recipe']['images'][0]['url']\n",
    "    totalTime = str(recipesMap[i]['recipe']['totalTimeMinutes']) + ' minutes' if recipesMap[i]['recipe']['totalTimeMinutes'] != None else '-'\n",
    "    rating = str(recipesMap[i]['rating']['ratingValue']) + '/5' if recipesMap[i]['rating'] != None else '-'\n",
    "    displayResults(title,img,totalTime,rating)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f4f3ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[vegetarian, or, gluten, -, free]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy as spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "sentence = 'vegetarian or gluten-free'\n",
    "idk = nlp(sentence)\n",
    "output = []\n",
    "for token in idk:\n",
    "    if(token.is_alpha):\n",
    "        toRemove = token.text\n",
    "    print\n",
    "    output.append(token)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98d749e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vegetarian', 'gluten-free', 'fish-free', 'nice']\n",
      "vegetarian\n",
      "gluten free\n",
      "fish free\n",
      "nice\n",
      "['gluten', 'fish']\n",
      "['vegetarian', 'nice']\n"
     ]
    }
   ],
   "source": [
    "import spacy as spacy\n",
    "from spacy import displacy\n",
    "\n",
    "\n",
    "def checkNegative(keyword):\n",
    "    return \"free\" in keyword or \"no\" in keyword\n",
    "\n",
    "def cleanNegativeWord(keyword):\n",
    "    keyword = keyword.replace(\"free\",\"\").strip()\n",
    "    keyword = keyword.replace(\"no \",\"\").strip()\n",
    "    return keyword\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "sentence = 'vegetarian or gluten-free or fish-free and nice'\n",
    "array = sentence.split()\n",
    "keywordsPositive = []\n",
    "keywordsNegative = []\n",
    "\n",
    "doc = nlp(sentence)\n",
    "for token in doc:\n",
    "    if(token.is_stop ):\n",
    "        array.remove(token.text)\n",
    "\n",
    "print(array)\n",
    "\n",
    "for keyword in array:\n",
    "    keywordDoc = nlp(keyword)\n",
    "    keywordString = ' '.join([token.lemma_ for token in keywordDoc if not token.is_stop and token.is_alpha])\n",
    "    print(keywordString)\n",
    "    if checkNegative(keyword):\n",
    "        keywordCleaned = cleanNegativeWord(keywordString)\n",
    "        keywordsNegative.append(keywordCleaned)\n",
    "    else:\n",
    "        keywordsPositive.append(keywordString)\n",
    "\n",
    "\n",
    "\n",
    "print(keywordsNegative)\n",
    "\n",
    "print(keywordsPositive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cec46b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2int(textnum, numwords={}):\n",
    "    if not numwords:\n",
    "      units = [\n",
    "        \"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\",\n",
    "        \"nine\", \"ten\", \"eleven\", \"twelve\", \"thirteen\", \"fourteen\", \"fifteen\",\n",
    "        \"sixteen\", \"seventeen\", \"eighteen\", \"nineteen\",\n",
    "      ]\n",
    "\n",
    "      tens = [\"\", \"\", \"twenty\", \"thirty\", \"forty\", \"fifty\", \"sixty\", \"seventy\", \"eighty\", \"ninety\"]\n",
    "\n",
    "      scales = [\"hundred\", \"thousand\", \"million\", \"billion\", \"trillion\"]\n",
    "\n",
    "      numwords[\"and\"] = (1, 0)\n",
    "      for idx, word in enumerate(units):    numwords[word] = (1, idx)\n",
    "      for idx, word in enumerate(tens):     numwords[word] = (1, idx * 10)\n",
    "      for idx, word in enumerate(scales):   numwords[word] = (10 ** (idx * 3 or 2), 0)\n",
    "\n",
    "    current = result = 0\n",
    "    for word in textnum.split():\n",
    "        if word not in numwords:\n",
    "          raise Exception(\"Illegal word: \" + word)\n",
    "\n",
    "        scale, increment = numwords[word]\n",
    "        current = current * scale + increment\n",
    "        if scale > 100:\n",
    "            result += current\n",
    "            current = 0\n",
    "\n",
    "    return result + current\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ada604cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2int(\"sixty\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e30e07544ccebc78dacd6421da111f7ec20c267e40e3fb45cd6c16b14155975"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('felixines': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
